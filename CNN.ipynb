{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYol4O9EhJD6",
        "outputId": "615535dc-b05d-4265-fc2e-103ec565ee06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "izi1l_4X5H74"
      },
      "outputs": [],
      "source": [
        " import torch\n",
        " import torch.nn as nn\n",
        " import torch.optim as optim\n",
        " from torchvision import datasets,transforms,models\n",
        " from torch.utils.data import DataLoader,random_split,Subset\n",
        " import matplotlib.pyplot as plt\n",
        " from PIL import ImageFile\n",
        " import os\n",
        " from PIL import Image\n",
        " ImageFile.LOAD_TRUNCATED_IMAGES=True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o_ZvR2tTFhde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.Resize((128,128)),transforms.ToTensor(),transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])"
      ],
      "metadata": {
        "id": "1_mvKJTlRLq6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/content/drive/MyDrive/PetImagesSampled'\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "train_size=int(0.7*len(dataset))\n",
        "val_size=int(0.15*len(dataset))\n",
        "test_size=len(dataset)-train_size-val_size\n",
        "train_dataset,val_dataset,test_dataset=random_split(dataset,[train_size,val_size,test_size])\n",
        "\n",
        "batch_size=64\n",
        "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "E755I-Y3giJQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self,n_classes):\n",
        "    super(SimpleCNN,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,16,kernel_size=3,padding=1)\n",
        "    self.pool=nn.MaxPool2d(2,2)\n",
        "    self.conv2=nn.Conv2d(16,32,kernel_size=3,padding=1)\n",
        "    self.fc1=nn.Linear(32*7*7,500)\n",
        "    self.fc2=nn.Linear(500,n_classes)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.adaptive_pool=nn.AdaptiveAvgPool2d((7,7))\n",
        "  def forward(self,x):\n",
        "    x=self.relu(self.conv1(x))\n",
        "    x=self.pool(x)\n",
        "    x=self.relu(self.conv2(x))\n",
        "    x=self.pool(x)\n",
        "    x=self.adaptive_pool(x)\n",
        "    x=x.view(-1,32*7*7)\n",
        "    x=self.relu(self.fc1(x))\n",
        "    x=self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "110nG0u0jV8o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import mobilenet_v2,MobileNet_V2_Weights\n",
        "weights=MobileNet_V2_Weights.DEFAULT\n",
        "mobilenet=mobilenet_v2(weights=weights)\n",
        "mobilenet.classifier[1]=nn.Linear(mobilenet.last_channel,2)"
      ],
      "metadata": {
        "id": "X1hyKIpjmTpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd1ea45-9e89-4f8a-98d1-09560565bb6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 60.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,criterion,train_loader,val_loader,num_epochs=5):\n",
        "  model=model.to(device)\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "    for inputs,labels in train_loader:\n",
        "      inputs,labels=inputs.to(device),labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs=model(inputs)\n",
        "      loss=criterion(outputs,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss+=loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}],Loss:{running_loss/len(train_loader):.4f}')\n",
        "    evaluate(model,val_loader)\n",
        "def evaluate(model,loader):\n",
        "  model.eval()\n",
        "  correct=0\n",
        "  total=0\n",
        "  with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "  print(f'Accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "C8M4-7sLptAD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "simple_cnn = SimpleCNN(n_classes=2).to(device)\n",
        "optimizer = optim.Adam(simple_cnn.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"Training SimpleCNN:\")\n",
        "train(simple_cnn, optimizer, criterion, train_loader, val_loader, num_epochs=5)\n",
        "print(\"\\nEvaluating SimpleCNN on test set:\")\n",
        "evaluate(simple_cnn, test_loader)\n",
        "\n",
        "mobilenet = mobilenet.to(device)\n",
        "optimizer_mobilenet = optim.Adam(mobilenet.parameters(), lr=0.001)\n",
        "print(\"\\nTraining MobileNetV2:\")\n",
        "train(mobilenet, optimizer_mobilenet, criterion, train_loader, val_loader, num_epochs=5)\n",
        "print(\"\\nEvaluating MobileNetV2 on test set:\")\n",
        "evaluate(mobilenet, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4vKX9Vns4HE",
        "outputId": "48ddeb05-f990-4873-c71f-defe8e77cb23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SimpleCNN:\n",
            "Epoch [1/5],Loss:0.6889\n",
            "Accuracy: 63.93%\n",
            "Epoch [2/5],Loss:0.6323\n",
            "Accuracy: 67.32%\n",
            "Epoch [3/5],Loss:0.5820\n",
            "Accuracy: 68.96%\n",
            "Epoch [4/5],Loss:0.5402\n",
            "Accuracy: 72.68%\n",
            "Epoch [5/5],Loss:0.5086\n",
            "Accuracy: 74.75%\n",
            "\n",
            "Evaluating SimpleCNN on test set:\n",
            "Accuracy: 74.15%\n",
            "\n",
            "Training MobileNetV2:\n",
            "Epoch [1/5],Loss:0.0487\n",
            "Accuracy: 94.86%\n",
            "Epoch [2/5],Loss:0.0493\n",
            "Accuracy: 97.05%\n",
            "Epoch [3/5],Loss:0.0283\n",
            "Accuracy: 97.16%\n",
            "Epoch [4/5],Loss:0.0176\n",
            "Accuracy: 96.94%\n",
            "Epoch [5/5],Loss:0.0257\n",
            "Accuracy: 94.21%\n",
            "\n",
            "Evaluating MobileNetV2 on test set:\n",
            "Accuracy: 94.11%\n"
          ]
        }
      ]
    }
  ]
}